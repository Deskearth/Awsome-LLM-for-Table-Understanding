[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)

# Awsome-LLM-for-Table-Understanding
A comprehensive paper list of Large Language Model for Table Understanding

## Contents
- [Tutorial](##tutorial)
- [Dataset](##dataset)
- [Paper](##paper)
  - [Survey](###survey)  
  - [Table Encoding](###table-encoding)
  - [Model Structure for Tabular Data](###model-structure-for-tabular-data)
  - [LLM Training with Tabular Data](###llm-training-with-tabular-data)
  - [LLM-driven Table Agents](###llm-driven-table-agents)

## Tutorial

## Dataset
* Fuse: a reproducible, extendable, internet-scale corpus of spreadsheets. [[Paper]](https://www.researchgate.net/profile/Justin-Smith-55/publication/308861425_Fuse_A_Reproducible_Extendable_Internet-Scale_Corpus_of_Spreadsheets/links/5a1ef938458515a4c3d42624/Fuse-A-Reproducible-Extendable-Internet-Scale-Corpus-of-Spreadsheets.pdf) [[Dataset]](https://static.barik.net/fuse/index.html)
* ToTTo: A Controlled Table-To-Text Generation Dataset. [[Paper]](https://arxiv.org/pdf/2004.14373) [[Dataset]](https://github.com/google-research-datasets/ToTTo)

## Paper

### Survey
* Table pre-training: A survey on model architectures, pre-training objectives, and downstream tasks. [[Paper]](https://arxiv.org/pdf/2201.09745)
* Large Language Model for Table Processing: A Survey. [[Paper]](https://arxiv.org/pdf/2402.05121)
* A Survey of Table Reasoning with Large Language Models. [[Paper]](https://arxiv.org/pdf/2402.08259)
* Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey [[Paper]](https://arxiv.org/pdf/2402.17944)

### Table Encoding
* Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs. [[Paper]](https://arxiv.org/pdf/2310.10358)
* GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. [[Paper]](https://arxiv.org/pdf/2305.13062)
* DBCopilot: Scaling Natural Language Querying to Massive Databases. [[Paper]](https://arxiv.org/pdf/2312.03463v1)
* Table-to-text generation by structure-aware seq2seq learning. [[Paper]](https://arxiv.org/pdf/1711.09724)
* Data-to-text generation with content selection and planning. [[Paper]](https://arxiv.org/pdf/1809.00582)
* Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data. [[Paper]](https://arxiv.org/pdf/2402.12424v3)
* Assessing GPT4-V on Structured Reasoning Tasks. [[Paper]](https://arxiv.org/pdf/2312.11524)
* Multimodal Table Understanding. [[Paper]](https://arxiv.org/pdf/2406.08100)
* TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy. [[Paper]](https://arxiv.org/pdf/2406.01326)
* Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities. [[Paper]](https://arxiv.org/pdf/2405.16234)
* Large Language Models are few(1)-shot Table Reasoners. [[Paper]](https://arxiv.org/pdf/2210.06710)
* TaPas: Weakly Supervised Table Parsing via Pre-training. [[Paper]](https://arxiv.org/pdf/2004.02349)
* TAPEX: Table Pre-training via Learning a Neural SQL Executor. [[Paper]](https://arxiv.org/pdf/2107.07653)
* An inner table retriever for robust table question answering. [[Paper]](https://aclanthology.org/2023.acl-long.551.pdf)
* LI-RAGE: Late interaction retrieval augmented generation with explicit signals for open-domain table question answering. [[Paper]](https://aclanthology.org/2023.acl-short.133.pdf)
* DB-GPT: Empowering Database Interactions with Private Large Language Models. [[Paper]](https://arxiv.org/pdf/2312.17449)


### LLM Training with Tabular Data
* TaPas: Weakly Supervised Table Parsing via Pre-training. [[Paper]](https://arxiv.org/pdf/2004.02349)
* TURL: table understanding through representation learning. [[Paper]](https://arxiv.org/pdf/2006.14806)
* TABBIE: Pretrained Representations of Tabular Data. [[Paper]](https://aclanthology.org/2021.naacl-main.270.pdf)
* StructGPT: A General Framework for Large Language Model to Reason over Structured Data. [[Paper]](https://arxiv.org/pdf/2305.09645)
* TAPEX: Table Pre-Training via Learning a Neural SQL Executor. [[Paper]](https://arxiv.org/pdf/2107.07653)
* Tablegpt: Table-tuned gpt for diverse table tasks. [[Paper]](https://arxiv.org/pdf/2310.09263)
* TableLlama: Towards Open Large Generalist Models for Tables. [[Paper]](https://arxiv.org/pdf/2311.09206)
* TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios. [[Paper]](https://arxiv.org/pdf/2403.19318)
* Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data. [[Paper]](https://arxiv.org/pdf/2402.12424v3)
* My Database User Is a Large Language Model. [[Paper]](https://www.scitepress.org/Papers/2024/126977/126977.pdf)
* LLM-Enhanced Data Management. [[Paper]](https://arxiv.org/pdf/2402.02643)
* DB-GPT: Empowering Database Interactions with Private Large Language Models. [[Paper]](https://arxiv.org/pdf/2312.17449)

### LLM-driven Table Agents
* Table Retrieval May Not Necessitate Table-specific Model Design. [[Paper]](https://aclanthology.org/2022.suki-1.5.pdf)
* CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets. [[Paper]](https://arxiv.org/pdf/2309.17428)
* Self-refine: Iterative refinement with self-feedback. [[Paper]](https://arxiv.org/pdf/2303.17651)
* DIN-SQL: Decomposed InContext Learning of Text-to-SQL with Self-Correction. [[Paper]](https://arxiv.org/pdf/2304.11015)
* Chain-of-table: Evolving tables in the reasoning chain for table understanding. [[Paper]](https://arxiv.org/abs/2401.04398)
* Large Language Models Are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning. [[Paper]](https://arxiv.org/pdf/2301.13808)
* ReAct: Synergizing Reasoning and Acting in Language Models. [[Paper]](https://arxiv.org/pdf/2210.03629)
* StructGPT: A General Framework for Large Language Model to Reason over Structured Data. [[Paper]](https://arxiv.org/pdf/2305.09645)
* TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning. [[Paper]](https://arxiv.org/pdf/2312.09039)
* Self-Consistency Improves Chain of Thought Reasoning in Language Models. [[Paper]](https://arxiv.org/pdf/2203.11171)
* SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models. [[Paper]](https://arxiv.org/abs/2305.19308)
* ReAcTable: Enhancing ReAct for Table Question Answering. [[Paper]](https://arxiv.org/pdf/2310.00815)
* Binding Language Models in Symbolic Languages. [[Paper]](https://arxiv.org/pdf/2210.02875)
* Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow. [[Paper]](https://arxiv.org/pdf/2306.07209)
* TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks. [[Paper]](https://arxiv.org/pdf/2401.12869)
